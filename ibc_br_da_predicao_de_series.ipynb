{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto: Análise de Anomalias em Série Temporal"
      ],
      "metadata": {
        "id": "ULDWNbG9cx5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BIMASTER - Trabalho de final de curso\n",
        "\n",
        "Nome: Alex Marques Campos\n",
        "\n",
        "Etapa 02.B: Detecção de anomalias via predição de séries"
      ],
      "metadata": {
        "id": "p_Zbz7ZuczLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo deste notebook é carregar os dados das séries históricas de interesse e observar se é possível utilizar predição de séries temporais para realizar a detecção de anomalias. Para isso, um modelo LSTM.\n",
        "\n",
        "O primeiro passo é carregar as bibliotecas necessárias ao processamento e os dados propriamente ditos, que estão armazenados nos arquivos CSV (_comma separated values_) armazenados no subdiretório './__dados__/'."
      ],
      "metadata": {
        "id": "wc9G5F-vm5cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração do ambiente de execução"
      ],
      "metadata": {
        "id": "R_KJarOpo-_o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fCR2V-wocZJl"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import matplotlib\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NOME_DIRETORIO_DADOS = 'dados'\n",
        "NOME_DIRETORIO_MODELOS = 'modelos'\n",
        "NOME_ARQUIVO_SERIE_IBCBR = 'serie_ibcbr.csv'"
      ],
      "metadata": {
        "id": "CY4fZhLloQgd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'pandas == {pd.__version__}')\n",
        "print(f'matplotlib == {matplotlib.__version__}')\n",
        "print(f'tensorflow == {tf.__version__}')"
      ],
      "metadata": {
        "id": "1yRvVVanoSu4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "172b4397-63a6-409d-9e4d-8d7cb03cb96b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pandas == 1.3.5\n",
            "matplotlib == 3.2.2\n",
            "tensorflow == 2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ajustamos o formato de apresentação padrão dos gráficos\n",
        "sns.set_theme(style=\"white\", palette=\"pastel\")"
      ],
      "metadata": {
        "id": "0oh4IvnCofu_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# habilitamos a visualização especial de dataframes disponível no\n",
        "# Google Colaboratory, para facilitar a exploração dos dados.\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ],
      "metadata": {
        "id": "VJS_UT3-ojaM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga dos dados"
      ],
      "metadata": {
        "id": "GeXhAXcEo6rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lembre-se de criar uma pasta chamada '/content/dados' no Google Colaboratory e enviar os arquivos '.csv' para essa pasta."
      ],
      "metadata": {
        "id": "iQzs87iqZs_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_dir_dados = Path('.') / NOME_DIRETORIO_DADOS\n",
        "path_arq_ibcbr = path_dir_dados / NOME_ARQUIVO_SERIE_IBCBR"
      ],
      "metadata": {
        "id": "Qggg6abNolqr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def carregar_csv(path_csv:Path) -> pd.DataFrame:\n",
        "  \"\"\"\n",
        "  Carrega os dados de um arquivo CSV em um dataframe de\n",
        "  forma padronizada no escopo do projeto.\n",
        "  path_csv : objeto Path que aponta para o arquivo.\n",
        "  \"\"\"\n",
        "  if (path_csv is None) or (not path_csv.is_file()):\n",
        "    raise ValueError(\"The given path object doesn't point to a valid csv file.\")\n",
        "\n",
        "  return pd.read_csv(path_csv,\n",
        "                   sep=',',\n",
        "                   parse_dates=True,\n",
        "                   infer_datetime_format=True,\n",
        "                   index_col=0,\n",
        "                   decimal='.',\n",
        "                   encoding='utf8')"
      ],
      "metadata": {
        "id": "NaLWJyWhrzDz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carregamos o arquivo de dado em um dataframe, para iniciar a análise\n",
        "df_ibcbr = carregar_csv(path_arq_ibcbr)"
      ],
      "metadata": {
        "id": "R8pdKHi2r2Pw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verificar_propriedades(id:int, nome:str, dataframe:pd.DataFrame) -> None:\n",
        "  \"\"\"\n",
        "  Imprime propriedades do dataframe nomeado para inspeção visual dos dados.\n",
        "  id: inteiro que identifica o dataframe.\n",
        "  nome: nome do dataframe\n",
        "  dataframe: objeto do dataframe\n",
        "  \"\"\"\n",
        "  print(f'[{id:03d}] Dataframe: {nome}')\n",
        "  print('-' * 5)\n",
        "  print(f'Shape: {dataframe.shape}')\n",
        "  print('-' * 5)\n",
        "  print(dataframe.head(4))\n",
        "  print('')"
      ],
      "metadata": {
        "id": "zs2X2xzVwPYs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verificamos se os dataframes foram carregados corretamente.\n",
        "series = {\n",
        "  'IBC-BR': df_ibcbr\n",
        "}\n",
        "\n",
        "for idx,serie in enumerate(series.items()):\n",
        "  verificar_propriedades(idx+1, serie[0], serie[1])"
      ],
      "metadata": {
        "id": "0RPLvBR7ua6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb1797b8-afd7-42a8-beaa-115abc4dd4d8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[001] Dataframe: IBC-BR\n",
            "-----\n",
            "Shape: (236, 1)\n",
            "-----\n",
            "             valor\n",
            "data              \n",
            "2003-01-01   96.15\n",
            "2003-02-01   98.67\n",
            "2003-03-01  103.41\n",
            "2003-04-01  102.19\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste ponto, temos todos os dados carregados em DataFrames pandas e prontos para análise."
      ],
      "metadata": {
        "id": "6wUhHFfz0Q8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predição de Série Temporal"
      ],
      "metadata": {
        "id": "Oh-HcaQB01qu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definição de funções auxiliares"
      ],
      "metadata": {
        "id": "yG_dgJSJBApl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Começamos definindo funções auxiliares ao processo de análise."
      ],
      "metadata": {
        "id": "tKgd48uj9wnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def configurar_ticks_anuais(ax):\n",
        "  '''\n",
        "  Procedimento auxiliar para configurar a exibição do eixo x\n",
        "  de um gráfico do matplotlib para dados de séries temporais\n",
        "  para os quais só sejam marcados os valores ano a ano.\n",
        "  '''\n",
        "  ax.xaxis.set_major_locator(matplotlib.dates.YearLocator(base=1))\n",
        "  ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter(\"%Y\"))"
      ],
      "metadata": {
        "id": "mk60_I2uPz8-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def desenhar_serie_com_anomalias(df:pd.DataFrame,\n",
        "                                 indice_anomalias:pd.core.indexes.datetimes.DatetimeIndex,\n",
        "                                 nome_serie:str='IBC-BR') -> None:\n",
        "  fig = plt.figure(figsize=(16,5))\n",
        "\n",
        "  plt.plot(df['valor'], 'b', label=f'Índice {nome_serie}')\n",
        "\n",
        "  for e in indice_anomalias:\n",
        "    plt.axvline(x=e, color='r', linestyle=':')\n",
        "\n",
        "  plt.legend(loc='best')\n",
        "  plt.ylabel(nome_serie)\n",
        "  plt.xlabel('Tempo')\n",
        "\n",
        "  # ajustamos o eixo x da figura para exibir ticks a cada ano\n",
        "  configurar_ticks_anuais(fig.axes[0])\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "GRfboQgChFwp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calcula_metricas_erro(y_pred,y_test, number_features):\n",
        "    rmse = math.sqrt(mean_squared_error(y_pred,y_test))\n",
        "    print('RMSE: ', rmse)\n",
        "\n",
        "    mse = mean_squared_error(y_pred,y_test)\n",
        "    print('MSE: ',mse)\n",
        "\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    print('MAPE: ',mape, '%')\n",
        "\n",
        "    r2 = r2_score(y_pred,y_test)\n",
        "    print('R2 Score: ', r2)\n",
        "\n",
        "    if (number_features is not None and number_features > 0):\n",
        "        number_samples = len(y_pred)\n",
        "        adj_r2_score = 1-(1-r2)*(number_samples-1)/(number_samples-number_features-1)\n",
        "        print('R2 Ajustado: ', adj_r2_score)"
      ],
      "metadata": {
        "id": "pahRHTmWcg_y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def montar_treino_teste_validacao_por_janela(dataset:np.array, \n",
        "                                             window_size:int=24,\n",
        "                                             test_size:float=0.15,\n",
        "                                             val_size:float=0.15,\n",
        "                                             random_state:int=None\n",
        "                                             ) -> Tuple[np.array, np.array, np.array, np.array, np.array, np.array]:\n",
        "    \"\"\"\n",
        "    Recebe um dataframe e o divide em conjuntos de treino, validação e teste\n",
        "    com janelas (dos conjuntos X) de tamanho definido.\n",
        "    \n",
        "    Parâmetros:\n",
        "    dataset      : Numpy array a ser dividido em treino, validação e teste.\n",
        "    window_size  : Tamanho da janela deslizante a ser aplicada ao dataset e também\n",
        "                   o tamanho de cada elemento dos conjuntos X.\n",
        "    test_size    : float entre 0.01 e 1.00, que representa o valor percentual do \n",
        "                   conjunto de teste com relação ao tamanho do dataset.\n",
        "    val_size     : float entre 0.01 e 1.00, que representa o valor percentual do \n",
        "                   conjunto de validação com relação ao tamanho do dataset.\n",
        "    random_state : inteiro que representa o estado randômico da execução do passo\n",
        "                   da escolha dos elementos de treino e teste.\n",
        "\n",
        "    Nota: test_size + val_size deve ser um valor menor do que 1.00, pois deve\n",
        "          existir um conjunto de treino.\n",
        "\n",
        "    Retorna: X_train, y_train, X_val, y_val, X_test e y_test, onde cada elemento\n",
        "             é um array numpy.\n",
        "    \"\"\"\n",
        "    data_size = len(dataset)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    if data_size < (window_size + 1):\n",
        "      raise ValueError(\"\"\"\n",
        "      The input data dimension 0's length should be at least window_size + 1.\n",
        "      \"\"\")\n",
        "\n",
        "    if test_size < 0.01 or test_size > 1.00:\n",
        "      raise ValueError('The value of test_size should be between 0.01 and 1.00')\n",
        "\n",
        "    if val_size < 0.01 or val_size > 1.00:\n",
        "      raise ValueError('The value of val_size should be between 0.01 and 1.00')\n",
        "    \n",
        "    if test_size + val_size >= 1.00:\n",
        "      raise ValueError('test_size + val_size should be less than 1.00')\n",
        "\n",
        "    for i in range(window_size, data_size):\n",
        "        X.append(dataset[i-window_size:i])\n",
        "        y.append(dataset[i])\n",
        "    X, y = np.array(X), np.array(y)\n",
        "\n",
        "    # na primeira chamada, dividimos o conjunto em treino e teste,\n",
        "    # onde o tamanho do conjunto de teste é explícito (default de 15%) e \n",
        "    # o tamanho do conjunto de treino fica proporcional a (1 - test_size) \n",
        "    # (default de 85%).\n",
        "    X_train_tmp, X_test, y_train_tmp, y_test = train_test_split(X, \n",
        "                                                                y, \n",
        "                                                                test_size=test_size,\n",
        "                                                                random_state=random_state)\n",
        "\n",
        "    # para obter o conjunto de validação, dividimos novamente o conjunto de \n",
        "    # treino, cujo tamanho agora é diretamente proprorcional a (1 - test_size),\n",
        "    # em duas partes, mas agora o conjunto de teste será nossa 'validação'.\n",
        "\n",
        "    # como val_size é referente a 100% e o conjunto agora é menor,\n",
        "    # recalculamos val_size para o tamanho atual do conjunto de treinamento\n",
        "    # antes de o dividir novamente.\n",
        "    val_size_recalculado = val_size / (1 - test_size)\n",
        "    \n",
        "    # dividimos novamente o conjunto, agora em treino e validação\n",
        "    # desabilitamos o shuffle porque ele é desnecessário.\n",
        "    # passamos o random_state só por completude (como shuffle está desabilitado\n",
        "    # esse argumento não deveria ter efeito na chamada).\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_tmp, \n",
        "                                                      y_train_tmp, \n",
        "                                                      test_size=val_size_recalculado,\n",
        "                                                      shuffle=False,\n",
        "                                                      random_state=random_state)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ],
      "metadata": {
        "id": "pm4yioxacjoJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imprimir_propriedades_aux(a_var:np.array, a_name:str) -> None:\n",
        "  print(f'Tamanho de {a_name} = {len(a_var)}')\n",
        "  if type(a_var[0]) == np.float64:\n",
        "    tam_elem = 1\n",
        "  else:\n",
        "    tam_elem = len(a_var[0])\n",
        "  print(f'   Tamanho de um elemento de {a_name} = {tam_elem}')"
      ],
      "metadata": {
        "id": "V0C7isgd8viL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imprimir_propriedades(X_train, y_train, X_val, y_val, X_test, y_test) -> None:\n",
        "  imprimir_propriedades_aux(X_train, 'X_train')\n",
        "  imprimir_propriedades_aux(y_train, 'y_train')\n",
        "  imprimir_propriedades_aux(X_val, 'X_val')\n",
        "  imprimir_propriedades_aux(y_val, 'y_val')\n",
        "  imprimir_propriedades_aux(X_test, 'X_test')\n",
        "  imprimir_propriedades_aux(y_test, 'y_test')"
      ],
      "metadata": {
        "id": "pgd4Tg4H7N1S"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuração do estado determinístico do processo"
      ],
      "metadata": {
        "id": "jPrFN-X8AtY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Depois fixamos as sementes randômicas, para que o processo seja previsível a cada execução."
      ],
      "metadata": {
        "id": "bpeXMipfd9gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# esse passo é essencial para a reprocibilidade do experimento\n",
        "random.seed(26)\n",
        "np.random.seed = 26"
      ],
      "metadata": {
        "id": "NmFIL4q0dGw_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SLIDING_WINDOW_SIZE=24\n",
        "TRAIN_BATCH_SIZE=20\n",
        "TRAIN_EPOCHS=300"
      ],
      "metadata": {
        "id": "HkTxuu4iJLSG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalização e separação dos dados nos conjuntos de treinamento, validação e teste"
      ],
      "metadata": {
        "id": "Wql0h5OrAgDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos os valores dos dados e os índices em dois objetos diferentes, pois não usaremos o índice temporal durante o treinamento."
      ],
      "metadata": {
        "id": "u6LqSZqfHg2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_valores = df_ibcbr['valor'].to_numpy()\n",
        "np_indice = df_ibcbr.index.to_numpy()"
      ],
      "metadata": {
        "id": "7btVkPMcHmk9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'np_valores.shape = {np_valores.shape}')\n",
        "print(f'np_indice.shape = {np_indice.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiwhXn6JK1gJ",
        "outputId": "58bfd4eb-0d6a-4332-860a-7f90bd488a51"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np_valores.shape = (236,)\n",
            "np_indice.shape = (236,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# aqui adicionamos uma coluna extra ao array de np_valores\n",
        "# para poder usar o scaler depois e normalizar os dados.\n",
        "np_valores_col_extra = np_valores.reshape(-1,1)\n",
        "np_valores_col_extra.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm7rbqZiLwoc",
        "outputId": "f75b1334-3f52-4cb7-b98d-fb6dd979365a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(236, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seguir, normalizamos os valores para realizar o processamento pelo modelo.\n",
        "\n",
        "É importante guardarmos o processo de normalização dos dados, para depois poder reconstruir os dados previstos."
      ],
      "metadata": {
        "id": "s0Y6k2WOGijw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# criamos o normalizador (scaler) e o guardamos na variável 'scaler'\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# treinamos o normalizador e já normalizamos os dados, os armazenado\n",
        "# na variável 'np_valores_col_extra'\n",
        "np_valores_col_extra = scaler.fit_transform(np_valores_col_extra)\n",
        "print(f'dimensões do np_valores_col_extra = {np_valores_col_extra.shape}')\n",
        "\n",
        "# depois jogamos fora a coluna extra que criamos só para poder utilizar\n",
        "# o scaler\n",
        "np_valores_norm = np_valores_col_extra.squeeze()\n",
        "print(f'dimensões do np_valores_norm = {np_valores_norm.shape}')"
      ],
      "metadata": {
        "id": "blKspGxDGmJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba7e65ae-9a94-435c-9686-680223d38526"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dimensões do np_valores_col_extra = (236, 1)\n",
            "dimensões do np_valores_norm = (236,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse ponto, temos os dados normalizados e prontos para a divisão nos conjuntos\n",
        "de treino, validação e teste."
      ],
      "metadata": {
        "id": "6GhS-f2T6YwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test = montar_treino_teste_validacao_por_janela(np_valores_norm,\n",
        "                                                                                          window_size=SLIDING_WINDOW_SIZE)"
      ],
      "metadata": {
        "id": "jcZM5fwgfP-V"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imprimir_propriedades(X_train, y_train, X_val, y_val, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFjH1Ho_8nnh",
        "outputId": "0a094e94-fa07-4309-d6f1-3042997607ba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho de X_train = 148\n",
            "   Tamanho de um elemento de X_train = 24\n",
            "Tamanho de y_train = 148\n",
            "   Tamanho de um elemento de y_train = 1\n",
            "Tamanho de X_val = 32\n",
            "   Tamanho de um elemento de X_val = 24\n",
            "Tamanho de y_val = 32\n",
            "   Tamanho de um elemento de y_val = 1\n",
            "Tamanho de X_test = 32\n",
            "   Tamanho de um elemento de X_test = 24\n",
            "Tamanho de y_test = 32\n",
            "   Tamanho de um elemento de y_test = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificação:\n",
        "\n",
        "148 (treino) + 32 (validação) + 32 (teste) = 212\n",
        "\n",
        "O somatório dos elementos nos conjuntos (212) com os 24 primeiros elementos começamos a partir do primeiro elemento de uma janela completa) resulta em 236 (tamanho original). Então está ok.\n",
        "\n",
        "Os dados também foram embaralhados durante a separação dos conjuntos, mas respeitando a coerencia temporal dentro de cada janela."
      ],
      "metadata": {
        "id": "EbF3n8KS-1Yh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo LSTM"
      ],
      "metadata": {
        "id": "Zk4maopEgq2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nossa primeira abordagem será treinar uma rede neural LSTM para fazer predição da série temporal IBC-BR original. Primeiro, para identificar os melhores hiper-parâmetros do modelo, treinaremos uma rede LSTM com todos os dados da série, divididos em janelas de 24 meses."
      ],
      "metadata": {
        "id": "iY-4vd-d1zTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input shape do LSTM\n",
        "n_samples  = len(X_train)\n",
        "n_input_features = SLIDING_WINDOW_SIZE\n",
        "n_labels = 1"
      ],
      "metadata": {
        "id": "MwdJtFuCI3aQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# definição da rede LSTM\n",
        "# usamos dropouts para aumentar a resiliência da rede. Evitamos os dropouts recorrentes\n",
        "# para que a implementação acelerada cuDNN possa ser utilizada.\n",
        "# documentação em https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM.\n",
        "\n",
        "model_lstm = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(240, input_shape=(n_input_features, n_labels), return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(80, return_sequences=False),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(24, activation='tanh'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])"
      ],
      "metadata": {
        "id": "UfQA9890-DZY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.compile(optimizer='adam', loss='mse')\n",
        "model_lstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ5Y1Zd8Lvlu",
        "outputId": "d3cf39f9-60e8-4e2a-ce12-f15896aae15b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 24, 240)           232320    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 24, 240)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 80)                102720    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 80)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24)                1944      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 24)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 337,009\n",
            "Trainable params: 337,009\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback_es = EarlyStopping(monitor='val_loss', \n",
        "                            min_delta=0,\n",
        "                            patience=10,\n",
        "                            verbose=1,\n",
        "                            mode='min')\n",
        "\n",
        "history = model_lstm.fit(x=X_train,\n",
        "                         y=y_train,\n",
        "                         validation_data=(X_val, y_val),\n",
        "                         batch_size=TRAIN_BATCH_SIZE,\n",
        "                         epochs=TRAIN_EPOCHS,\n",
        "                         shuffle=False,\n",
        "                         callbacks =[callback_es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLXlcFC_SlBK",
        "outputId": "4601c301-c1f1-4a63-9719-628a4664fc48"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "8/8 [==============================] - 14s 558ms/step - loss: 0.1404 - val_loss: 0.0558\n",
            "Epoch 2/300\n",
            "8/8 [==============================] - 1s 181ms/step - loss: 0.0418 - val_loss: 0.0087\n",
            "Epoch 3/300\n",
            "8/8 [==============================] - 2s 208ms/step - loss: 0.0319 - val_loss: 0.0200\n",
            "Epoch 4/300\n",
            "8/8 [==============================] - 2s 188ms/step - loss: 0.0268 - val_loss: 0.0074\n",
            "Epoch 5/300\n",
            "8/8 [==============================] - 1s 124ms/step - loss: 0.0310 - val_loss: 0.0099\n",
            "Epoch 6/300\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.0237 - val_loss: 0.0066\n",
            "Epoch 7/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.0228 - val_loss: 0.0094\n",
            "Epoch 8/300\n",
            "8/8 [==============================] - 1s 102ms/step - loss: 0.0224 - val_loss: 0.0075\n",
            "Epoch 9/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.0202 - val_loss: 0.0069\n",
            "Epoch 10/300\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.0200 - val_loss: 0.0076\n",
            "Epoch 11/300\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.0178 - val_loss: 0.0087\n",
            "Epoch 12/300\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.0185 - val_loss: 0.0121\n",
            "Epoch 13/300\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.0246 - val_loss: 0.0057\n",
            "Epoch 14/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.0174 - val_loss: 0.0085\n",
            "Epoch 15/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.0222 - val_loss: 0.0071\n",
            "Epoch 16/300\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.0162 - val_loss: 0.0071\n",
            "Epoch 17/300\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.0176 - val_loss: 0.0058\n",
            "Epoch 18/300\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.0179 - val_loss: 0.0060\n",
            "Epoch 19/300\n",
            "8/8 [==============================] - 1s 87ms/step - loss: 0.0184 - val_loss: 0.0104\n",
            "Epoch 20/300\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.0175 - val_loss: 0.0056\n",
            "Epoch 21/300\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.0196 - val_loss: 0.0136\n",
            "Epoch 22/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.0230 - val_loss: 0.0065\n",
            "Epoch 23/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.0166 - val_loss: 0.0057\n",
            "Epoch 24/300\n",
            "8/8 [==============================] - 1s 86ms/step - loss: 0.0173 - val_loss: 0.0132\n",
            "Epoch 25/300\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.0171 - val_loss: 0.0061\n",
            "Epoch 26/300\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.0178 - val_loss: 0.0099\n",
            "Epoch 27/300\n",
            "8/8 [==============================] - 1s 84ms/step - loss: 0.0147 - val_loss: 0.0086\n",
            "Epoch 28/300\n",
            "8/8 [==============================] - 1s 82ms/step - loss: 0.0208 - val_loss: 0.0059\n",
            "Epoch 29/300\n",
            "8/8 [==============================] - 1s 85ms/step - loss: 0.0168 - val_loss: 0.0093\n",
            "Epoch 30/300\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.0173 - val_loss: 0.0061\n",
            "Epoch 30: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "128KOPX8UOAi"
      },
      "execution_count": 28,
      "outputs": []
    }
  ]
}